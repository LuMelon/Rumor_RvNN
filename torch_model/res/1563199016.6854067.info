2019-07-15 21:56:56,686 2883 Namespace(Adadelta=False, Adagrad=True, Adam=False, T_step=5, batch_size=25, child_sum=False, dropout=0.5, epochs=100, gpu=0, graph_transformer=False, h_size=256, log_every=5, logfile='./tmp.log', lr=0.05, modelId='1563199016.6854067', seed=41, tree_lstm=False, weight_decay=0.0001, x_size=256)
2019-07-15 21:57:11,283 2883 GraphTransformer(
  (embedding): Embedding(19536, 256)
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (cell): TransformerCell(
    (attnLayer1): MultiHeadedAttention(
      (linears): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
      )
      (dropout): Dropout(p=0.1)
    )
    (attnLayer2): MultiHeadedAttention(
      (linears): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
      )
      (dropout): Dropout(p=0.1)
    )
    (layerNorm1): LayerNorm()
    (layerNorm2): LayerNorm()
  )
)
